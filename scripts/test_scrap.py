import os
import time
import re
import random
import psycopg2
from psycopg2.extras import execute_values
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from tqdm import tqdm
import pandas as pd
from datetime import datetime

# Charger les variables d'environnement
load_dotenv()

DB_USER = os.getenv("POSTGRES_USER")
DB_PASSWORD = os.getenv("POSTGRES_PASSWORD")
DB_NAME = os.getenv("POSTGRES_DB")
DB_PORT = os.getenv("POSTGRES_PORT", 5432)

# Liste de User-Agents pour rotation (simule diff√©rents navigateurs/utilisateurs)
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/120.0.0.0',
]

# Connexion √† PostgreSQL
def get_connection():
    return psycopg2.connect(
        dbname=DB_NAME,
        user=DB_USER,
        password=DB_PASSWORD,
        host="localhost",
        port=DB_PORT
    )

def get_random_headers():
    """G√©n√®re des headers al√©atoires pour simuler diff√©rents utilisateurs"""
    return {
        'User-Agent': random.choice(USER_AGENTS),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
        'Accept-Language': random.choice(['fr-FR,fr;q=0.9,en;q=0.8', 'en-US,en;q=0.9', 'fr;q=0.9,en-US;q=0.8,en;q=0.7']),
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Cache-Control': 'max-age=0',
        'DNT': '1',
    }

def random_delay(min_seconds=3, max_seconds=7):
    """Pause al√©atoire pour simuler un comportement humain"""
    delay = random.uniform(min_seconds, max_seconds)
    time.sleep(delay)

def clean_text(text):
    """Nettoie le texte en supprimant les espaces superflus"""
    if text:
        return ' '.join(text.strip().split())
    return None

def parse_number(text):
    """Extrait un nombre d'un texte, retourne 0 si pas de nombre"""
    if not text:
        return 0
    
    # Enlever les espaces et tirets
    text = text.strip().replace(' ', '').replace('\n', '')
    
    # Si c'est un tiret seul, retourner 0
    if text == '-' or text == '':
        return 0
    
    # Extraire le premier nombre trouv√©
    match = re.search(r'\d+', text)
    if match:
        return int(match.group())
    
    return 0

def parse_date(date_str):
    """Parse les dates dans diff√©rents formats"""
    if not date_str:
        return None
    
    # Format: "28 d√©c. 2004 (20)"
    date_match = re.search(r'(\d{1,2})\s+(\w+\.?)\s+(\d{4})', date_str)
    if date_match:
        day, month_abbr, year = date_match.groups()
        
        # Mapping des mois fran√ßais
        months_fr = {
            'janv': '01', 'f√©vr': '02', 'mars': '03', 'avr': '04',
            'mai': '05', 'juin': '06', 'juil': '07', 'ao√ªt': '08',
            'sept': '09', 'oct': '10', 'nov': '11', 'd√©c': '12'
        }
        
        month_key = month_abbr.replace('.', '').lower()
        month = months_fr.get(month_key, '01')
        
        try:
            return f"{year}-{month}-{day.zfill(2)}"
        except:
            return None
    
    return None

def get_player_info(url, session, retry=3):
    """R√©cup√®re les informations du joueur depuis Transfermarkt"""
    
    for attempt in range(retry):
        try:
            # Headers al√©atoires √† chaque tentative
            headers = get_random_headers()
            
            # Ajouter un d√©lai al√©atoire avant la requ√™te (sauf premi√®re tentative)
            if attempt > 0:
                print(f"   ‚è≥ Pause de {5 + attempt * 2}s avant nouvelle tentative...")
                time.sleep(5 + attempt * 2)
            
            response = session.get(url, headers=headers, timeout=25)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Nom du joueur
            name = None
            name_elem = soup.find("h1", class_="data-header__headline-wrapper")
            if name_elem:
                # Enlever le num√©ro de maillot
                name_text = name_elem.get_text()
                name = re.sub(r'#\d+\s*', '', name_text).strip()
            
            # Date de naissance
            birth_date = None
            birth_elem = soup.find("span", itemprop="birthDate")
            if birth_elem:
                birth_date = parse_date(birth_elem.get_text())
            
            # Alternative: chercher dans la page
            if not birth_date:
                birth_match = re.search(r'(\d{1,2})\s+(\w+\.?)\s+(\d{4})\s*\((\d+)\)', soup.get_text())
                if birth_match:
                    birth_date = parse_date(birth_match.group(0))
            
            # Nationalit√©
            nationality = None
            nationality_elem = soup.find("span", itemprop="nationality")
            if nationality_elem:
                nationality = clean_text(nationality_elem.get_text())
            
            # Alternative pour la nationalit√©
            if not nationality:
                flag_imgs = soup.find_all("img", class_="flaggenrahmen")
                for img in flag_imgs:
                    alt_text = img.get('alt', '')
                    if 'S√©n√©gal' in alt_text or 'Senegal' in alt_text:
                        nationality = 'S√©n√©gal'
                        break
            
            # Position
            position = None
            # Chercher dans data-header__label
            labels = soup.find_all("li", class_="data-header__label")
            for label in labels:
                text = label.get_text()
                # Si √ßa contient "Arri√®re", "Milieu", "Attaquant", "Gardien"
                if any(keyword in text for keyword in ["Arri√®re", "Milieu", "Attaquant", "Gardien", "D√©fenseur"]):
                    position = clean_text(text)
                    break
            
            # Club actuel
            club = None
            club_elem = soup.find("span", class_="data-header__club")
            if club_elem:
                club_link = club_elem.find("a")
                if club_link:
                    club = clean_text(club_link.get_text())
            
            return {
                "name": name,
                "birth_date": birth_date,
                "nationality": nationality,
                "position": position,
                "current_club": club,
                "url": url
            }
        
        except requests.exceptions.Timeout:
            if attempt < retry - 1:
                print(f"   ‚è±Ô∏è  Timeout (tentative {attempt + 1}/{retry})")
                continue
            else:
                print(f"   ‚ùå Timeout apr√®s {retry} tentatives")
                return None
        
        except requests.exceptions.RequestException as e:
            if attempt < retry - 1:
                print(f"   ‚ö†Ô∏è  Erreur r√©seau (tentative {attempt + 1}/{retry})")
                continue
            else:
                print(f"   ‚ùå Erreur r√©seau: {type(e).__name__}")
                return None
        
        except Exception as e:
            print(f"   ‚ùå Erreur: {type(e).__name__}")
            return None
    
    return None

def get_player_stats(url, session, retry=3):
    """R√©cup√®re les statistiques de la saison EN COURS (2024/25 ou 2025/26)"""
    
    # # URL de la page des performances pour la saison 2024/25
    # # Transfermarkt utilise l'ann√©e de d√©but de saison (2024 pour 2024/25)
    # stats_url = url.replace('/profil/', '/leistungsdatendetails/')
    # stats_url = stats_url + '/saison/2024/verein/0/liga/0/wettbewerb//pos/0/trainer_id/0/plus/1'

    # URL de la page des performances pour la saison 2025/26
    # Transfermarkt utilise l‚Äôann√©e de d√©but de saison (2025 pour 2025/26)
    stats_url = url.replace('/profil/', '/leistungsdatendetails/')
    stats_url = stats_url + '/saison/2025/verein/0/liga/0/wettbewerb//pos/0/trainer_id/0/plus/1'

    
    for attempt in range(retry):
        try:
            # Headers al√©atoires √† chaque tentative
            headers = get_random_headers()
            
            # Ajouter un petit d√©lai al√©atoire entre info et stats (comportement humain)
            random_delay(2, 4)
            
            if attempt > 0:
                print(f"   ‚è≥ Pause de {5 + attempt * 2}s avant nouvelle tentative...")
                time.sleep(5 + attempt * 2)
            
            response = session.get(stats_url, headers=headers, timeout=25)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Chercher le tableau avec la classe 'items'
            table = soup.find("table", class_="items")
            
            if not table:
                print("   ‚ö†Ô∏è  Tableau non trouv√©")
                return None
            
            # Chercher d'abord dans le FOOTER (contient les totaux)
            footer = table.find("tfoot")
            
            if footer:
                cells = footer.find_all("td")
                footer_values = [clean_text(c.get_text()) for c in cells]
                
                # Structure du footer Transfermarkt:
                # ['', 'Total:', '', '', '176', '169', '1,38', '64', '9', '-', '73', '42', '6', '-', '2', '6', "146'", "9.326'"]
                # Index typiques: 4=Matchs, 7=Buts, 8=Passes d√©cisives
                
                total_matches = 0
                total_goals = 0
                total_assists = 0
                
                # Trouver les indices des statistiques
                for i, val in enumerate(footer_values):
                    num = parse_number(val)
                    
                    # Les matchs sont g√©n√©ralement √† l'index 4
                    if i == 4 and num > 0:
                        total_matches = num
                    # Les buts √† l'index 7
                    elif i == 7 and num >= 0:
                        total_goals = num
                    # Les passes √† l'index 8
                    elif i == 8 and num >= 0:
                        total_assists = num
                
                if total_matches > 0:
                    print(f"   üéØ {total_matches} matchs | {total_goals} buts | {total_assists} passes")
                    
                    return {
                        "matches_played": total_matches,
                        "goals": total_goals,
                        "assists": total_assists,
                        "minutes_played": total_matches * 90
                    }
            
            # Fallback: lire le tbody si pas de footer
            tbody = table.find("tbody")
            if tbody:
                rows = tbody.find_all("tr")
                
                total_matches = 0
                total_goals = 0
                total_assists = 0
                
                for row in rows:
                    cells = row.find_all("td")
                    
                    if len(cells) >= 5:
                        matches = parse_number(cells[1].get_text())
                        goals = parse_number(cells[3].get_text())
                        assists = parse_number(cells[4].get_text())
                        
                        total_matches += matches
                        total_goals += goals
                        total_assists += assists
                
                if total_matches > 0:
                    print(f"   üéØ {total_matches} matchs | {total_goals} buts | {total_assists} passes")
                    
                    return {
                        "matches_played": total_matches,
                        "goals": total_goals,
                        "assists": total_assists,
                        "minutes_played": total_matches * 90
                    }
            
            print("   ‚ö†Ô∏è  Aucune statistique")
            return None
        
        except requests.exceptions.Timeout:
            if attempt < retry - 1:
                print(f"   ‚è±Ô∏è  Timeout stats (tentative {attempt + 1}/{retry})")
                continue
            else:
                print(f"   ‚ùå Timeout stats apr√®s {retry} tentatives")
                return None
        
        except requests.exceptions.RequestException as e:
            if attempt < retry - 1:
                print(f"   ‚ö†Ô∏è  Erreur r√©seau stats (tentative {attempt + 1}/{retry})")
                continue
            else:
                print(f"   ‚ùå Erreur r√©seau stats: {type(e).__name__}")
                return None
        
        except Exception as e:
            print(f"   ‚ùå Erreur stats: {type(e).__name__}")
            return None
    
    return None

def upsert_player(conn, info, stats):
    """Ins√®re ou met √† jour un joueur dans la base de donn√©es"""
    if not info or not info.get('name'):
        print("   ‚ö†Ô∏è  Informations incompl√®tes")
        return
    
    try:
        with conn.cursor() as cur:
            # V√©rifier si le joueur existe
            cur.execute(
                "SELECT player_id FROM players WHERE name = %s",
                (info["name"],)
            )
            player = cur.fetchone()
            
            if player:
                player_id = player[0]
                
                # Mettre √† jour les infos du joueur
                cur.execute("""
                    UPDATE players 
                    SET birth_date = COALESCE(%s, birth_date),
                        nationality = COALESCE(%s, nationality),
                        position = COALESCE(%s, position),
                        current_club = COALESCE(%s, current_club)
                    WHERE player_id = %s
                """, (
                    info["birth_date"],
                    info["nationality"],
                    info["position"],
                    info["current_club"],
                    player_id
                ))
                
                # V√©rifier si une performance agr√©g√©e existe d√©j√†
                if stats:
                    cur.execute("""
                        SELECT perf_id FROM performances 
                        WHERE player_id = %s AND match_id IS NULL
                    """, (player_id,))
                    
                    existing_perf = cur.fetchone()
                    
                    if existing_perf:
                        # Mettre √† jour
                        cur.execute("""
                            UPDATE performances
                            SET goals = %s,
                                assists = %s,
                                minutes_played = %s
                            WHERE perf_id = %s
                        """, (
                            stats["goals"],
                            stats["assists"],
                            stats["minutes_played"],
                            existing_perf[0]
                        ))
                    else:
                        # Cr√©er
                        cur.execute("""
                            INSERT INTO performances (player_id, match_id, minutes_played, goals, assists)
                            VALUES (%s, NULL, %s, %s, %s)
                        """, (
                            player_id,
                            stats["minutes_played"],
                            stats["goals"],
                            stats["assists"]
                        ))
            else:
                # Ins√©rer un nouveau joueur
                cur.execute("""
                    INSERT INTO players (name, birth_date, nationality, position, current_club)
                    VALUES (%s, %s, %s, %s, %s)
                    RETURNING player_id
                """, (
                    info["name"],
                    info["birth_date"],
                    info["nationality"],
                    info["position"],
                    info["current_club"]
                ))
                player_id = cur.fetchone()[0]
                
                # Ins√©rer les stats
                if stats:
                    cur.execute("""
                        INSERT INTO performances (player_id, match_id, minutes_played, goals, assists)
                        VALUES (%s, NULL, %s, %s, %s)
                    """, (
                        player_id,
                        stats["minutes_played"],
                        stats["goals"],
                        stats["assists"]
                    ))
        
        conn.commit()
        print(f"   ‚úÖ Enregistr√©")
        
    except Exception as e:
        conn.rollback()
        print(f"   ‚ùå Erreur DB: {type(e).__name__}")
        raise

def scrape_all_players():
    """Fonction principale de scraping"""
    conn = get_connection()
    
    # Cr√©er une session pour r√©utiliser les connexions (plus r√©aliste)
    session = requests.Session()
    
    # CSV avec les URLs
    players_csv = "data/raw/senegal_players_list.csv"
    
    if not os.path.exists(players_csv):
        print(f"‚ùå Fichier {players_csv} introuvable")
        return
    
    df_urls = pd.read_csv(players_csv)
    print(f"\n{'='*70}")
    print(f"üöÄ SCRAPING TRANSFERMARKT - JOUEURS S√âN√âGALAIS")
    print(f"{'='*70}")
    print(f"üìã {len(df_urls)} joueurs √† traiter")
    print(f"üé≠ Rotation de {len(USER_AGENTS)} User-Agents")
    print(f"‚è±Ô∏è  D√©lais al√©atoires: 3-7 secondes entre requ√™tes\n")
    
    success_count = 0
    error_count = 0
    skipped_count = 0
    
    for idx, row in df_urls.iterrows():
        url = row["url"]
        
        print(f"\n{'‚îÄ'*70}")
        print(f"[{idx+1}/{len(df_urls)}] üîó Traitement...")
        
        try:
            # R√©cup√©rer les infos
            info = get_player_info(url, session)
            
            if not info or not info.get('name'):
                print(f"   ‚è≠Ô∏è  Ignor√©: infos manquantes")
                error_count += 1
                random_delay(2, 4)  # Pause m√™me en cas d'erreur
                continue
            
            print(f"   üë§ {info['name']}")
            
            # V√©rifier la nationalit√©
            if info["nationality"] and "S√©n√©gal" in info["nationality"]:
                # R√©cup√©rer les stats
                stats = get_player_stats(url, session)
                
                # Ins√©rer dans la base
                upsert_player(conn, info, stats)
                success_count += 1
            else:
                print(f"   ‚è≠Ô∏è  Autre nationalit√©: {info.get('nationality', 'N/A')}")
                skipped_count += 1
        
        except Exception as e:
            print(f"   ‚ùå Erreur: {type(e).__name__}")
            error_count += 1
        
        # Pause al√©atoire entre joueurs (simule comportement humain)
        if idx < len(df_urls) - 1:  # Pas de pause apr√®s le dernier
            delay = random.uniform(4, 8)
            print(f"   ‚è≥ Pause de {delay:.1f}s avant le prochain joueur...")
            time.sleep(delay)
    
    session.close()
    conn.close()
    
    print(f"\n{'='*70}")
    print(f"‚úÖ SCRAPING TERMIN√â!")
    print(f"{'='*70}")
    print(f"   ‚úì Succ√®s:              {success_count} joueurs")
    print(f"   ‚äò Autre nationalit√©:   {skipped_count} joueurs")
    print(f"   ‚úó Erreurs:             {error_count} joueurs")
    print(f"{'='*70}\n")

if __name__ == "__main__":
    scrape_all_players()